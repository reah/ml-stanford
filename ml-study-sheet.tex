%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% Machine Learning by Stanford University
% Professor Andrew Ng
% Study Sheet by Reah Miyara <ml@reah.me>
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage[landscape]{geometry}
\usepackage{url}
\usepackage{multicol}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage{hyperref}
\usetikzlibrary{decorations.pathmorphing}
\usepackage{amsmath,amssymb}
\usepackage{tikz}
\usetikzlibrary{calc,trees,positioning,arrows,chains,shapes.geometric,%
    decorations.pathreplacing,decorations.pathmorphing,shapes,%
    matrix,shapes.symbols}

\tikzset{
>=stealth',
  punktchain/.style={
    rectangle, 
    rounded corners, 
    % fill=black!10,
    draw=black, thick,
    text width=4em, 
    minimum height=1em, 
    text centered, 
    on chain},
  line/.style={draw, thin, <-},
  element/.style={
    tape,
    top color=white,
    bottom color=blue!50!black!60!,
    minimum width=5em,
    draw=blue!40!black!90, very thick,
    text width=7em, 
    minimum height=2.5em, 
    text centered, 
    on chain},
  every join/.style={->, thick,shorten >=1pt},
  decoration={brace},
  tuborg/.style={decorate},
  tubnode/.style={midway, right=2pt},
}

\usepackage{colortbl}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{amsmath,amssymb}
\usepackage{enumitem}
\usepackage[misc]{ifsym}

\title{Machine Learning}
\usepackage[brazilian]{babel}
\usepackage[utf8]{inputenc}

\advance\topmargin-.8in
\advance\textheight3in
\advance\textwidth3in
\advance\oddsidemargin-1.5in
\advance\evensidemargin-1.5in
\newcommand{\sbt}{\,\begin{picture}(-1,1)(-1,-3)\circle*{3}\end{picture}\ }
\parindent0pt
\parskip2pt
\newcommand{\hr}{\centerline{\rule{3.5in}{1pt}}}
%\colorbox[HTML]{e4e4e4}{\makebox[\textwidth-2\fboxsep][l]{texto}
\begin{document}

\begin{center}{\huge{\textbf{Machine Learning by Stanford University}}}\\
	{\large \texttt{Study Sheet by Reah Miyara \href{mailto:ml@reah.me}{\Letter \hspace{3pt}ml@reah.me}}}
\end{center}
\begin{multicols*}{3}
	
	\tikzstyle{mybox} = [draw=black, fill=white, very thick,
	rectangle, rounded corners, inner sep=10pt, inner ysep=10pt]
	\tikzstyle{fancytitle} =[fill=white, text={rgb:yellow,2;green,4;blue,9}, font=\bfseries]
	%------------ Intro to Machine Learning ---------------
	\begin{tikzpicture}
		\node [mybox] (box){%
			\begin{minipage}{0.3\textwidth}
				\textbf{$\sbt$ ML} -- a computer program with increased performance $P$ at some class of tasks $T$ with experience $E$. \\
				\textbf{$\sbt$ Supervised} -- given a ['ground truth'] data set, predict output given the input. Types of prediction:
				\begin{enumerate}
					\itemsep0em 
					\item \textbf{Regression} -- continuous, numerical
					\item \textbf{Classification} -- discrete, categorical  
				\end{enumerate}
				        
				\textbf{$\sbt$ Unsupervised} -- derive structure from data based on relationships among variables (with no prior knowledge as to what the results should look like)
			\end{minipage}
		};
		\node[fancytitle, right=10pt] at (box.north west) {Intro to Machine Learning};
	\end{tikzpicture}
	
	%------------ Linear Regression with One Variable ---------------
	\begin{tikzpicture}
		\node [mybox] (box){%
			\begin{minipage}{0.3\textwidth}
				\textbf{$\sbt$ Learning Goal} -- given a training set, learn a function $h$: X$\rightarrow$Y so $h(x)$ is a good $y$ predictor
				    
				\begin{center}
					\tiny\begin{tikzpicture}
					[node distance=.5cm,
					start chain=going below,]
					\node[punktchain, join] (perfekt) {Training Set};
					\node[punktchain, join, ] (emperi) {Learning Algorithm};
					\node (asym) [punktchain, join ]  {function $h$: X$\rightarrow$Y};
					\begin{scope}[start branch=venstre,
							%We need to redefine the join-style to have the -> turn out right
						every join/.style={->, thick, shorten <=1pt}, ]
						\node[punktchain, on chain=going left, join=by {<-}]
						() {X};
					\end{scope}
					\begin{scope}[start branch=hoejre,]
						\node () [punktchain, on chain=going right, join=by {->}] {prediction Y};
					\end{scope}
					\end{tikzpicture}
				\end{center}
				  
				\textbf{$\sbt$ Hypothesis} -- $h_\theta(x) = \theta_0 + \theta_1x$ \\
				\textbf{$\sbt$ Cost Function} -- takes an average difference of all results of the hypothesis with inputs from the $x$ values and the actual $y$ values. Goal: minimize $\theta_0,\theta_1$\vspace{-10pt}
				\begin{equation}
				J(\theta_0, \theta_1) = \frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x_i)-y_i)^2 
				\vspace{-5pt}\end{equation}
				{\tiny(1) Squared Error function or Mean Squared Error function}\\
				\textbf{$\sbt$ Gradient Descent Algorithm} {\tiny repeat until convergence}
				\vspace{-10pt}\begin{equation}
				\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta_0, \theta_1)
				\end{equation}
			\end{minipage}
		};
		\node[fancytitle, right=10pt] at (box.north west) {Linear Regression with One Variable};
	\end{tikzpicture}
	
	
	\columnbreak
	
%------------ Multivariate Linear Regression ---------------
	\begin{tikzpicture}
		\node [mybox] (box){%
			\begin{minipage}{0.3\textwidth}
				$h_{\theta}(x)$ = 
				$\begin{bmatrix}
					\theta_{0} & \theta_{1} & \dots & \theta_{n}
				\end{bmatrix}$
				$\begin{bmatrix}
					x_{0}\\ 
					x_{1}\\ 
					\vdots\\ 
					x_{n}
				\end{bmatrix}$
				= $\theta^{T}x$
				
				\textbf{$\sbt$ Gradient Descent Algorithm} {\tiny repeat until convergence}
				\vspace{-10pt}\begin{equation}
				\theta_j := \theta_j - \alpha \frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)}-y^{(i)})\cdot x_j^{(i)} \text{ ; j:= 0\dots n} 
				\end{equation}
				
				\vspace{-5pt}
				\textbf{$\sbt$ Feature Scaling} -- divide the input values by the range (max -- min). Input values in roughly the same range speed up the convergence of gradient descent.\\
				\textbf{$\sbt$ Mean Normalization} -- subtract the mean for an input variable from the values for that input variable.
				\vspace{-5pt}\begin{equation}
				    x_i := \frac{x_i - \mu_i}{s_i}
				\end{equation}
				{\tiny(4) $\mu_i$ is the average and $s_i$ is the range, $(max-min)$, of all values for feature $i$}\\
			\end{minipage}
		};
		\node[fancytitle, right=10pt] at (box.north west) {Multivariate Linear Regression};
	\end{tikzpicture}
	
		\end{multicols*}
\end{document}
